syntax = "proto3";

package mldb;

enum FeatureType {
  UNKNOWN = 0;  // if we can't infer the feature type.
  CATEGORICAL = 1;  // int32
  NUMERICAL = 2;    // float
  BYTES = 3;  // arbitrary byte string.
  // Comment(wdai): timestamp should be a numerical type (in seconds).
  // TODO(wdai): What if user wants to store double? Ignore this for now.
}

// FeatureStoreType should be determined by the frequency of a feature in
// a dataset. This can be inferred at first ingest (schema creation) or
// explicitly/manually determined by user.
//
// Comment(wdai): See Dato's nice column type inference from data.
enum FeatureStoreType {
  DYNAMIC = 0;  // let the system decide.
  SPARSE = 1;
  DENSE = 2;
}

message FeatureStats {
  // max + 1 is assumed to be the # of unique values for CATEGORICAL features.
  double max = 5;

  double mean = 1;
  double std = 2;
  double quantile_5 = 3;
  double quantile_95 = 4;
}

message EpochInfo {

  // Comment (yuwr:) This should be a schema index? We might have many
  // schemas, each schema could have many versions.  Each epoch would
  // correspond to a schema, but not vice versa, hence the index.
  //
  // Comment (wdai): Since schema really is just the mapping from "mobile:ctr"
  // feature descriptor to the feature id, I feel that this only needs to
  // change when (1) user changes schema explicitly, or (2) we change the
  // internal descriptor to feature_id mapping. I feel (2) could be too costly
  // to do and thus we only needs one version id.

  // uint32 schema_id = 1;
  uint32 schema_version = 1;   // for schema evolution (future work).

  // # data in this epoch.
  uint64 num_data = 2;

  // # of outlier data determined at ingest time.
  uint64 num_outliers = 3;

  // Ingest period in unix time seconds.
  uint64 ingest_time_begin = 4;
  uint64 ingest_time_end = 5;

  // We assue each epoch would have one single FileMap object to locate the files.
  // We use the file map index to located the object, avoiding ojbect inconsistency.
  uint32 file_map_id= 7;
}

// Feature locates the feature value in DatumRecord, which has 6 data stores
// (3 FeatureType x 2 FeatureStoreType). FeatureType and FeatureStorage type
// identify the store in DatumRecord, and idx searches for the value in the
// appropriate store.
//
// Current max proto sequence: 8.
message Feature {
  string name = 6;
  FeatureType type = 1;
  FeatureStoreType storage_type = 2;

  // Locate feature value in the store. It represents the index for dense
  // store (vector) or key in sparse store (map), relative to the family's
  // offset. For example, for dense categorical feature "fam:feat", family
  // 'fam' has dense categorical offset of 10, and 'family_offset' = 3, then "fam:feat"
  // value is stored in DatumProto's dense_cat_store[13]. For map lookup, not
  // found means 0. This index is determined at schema creation.
  uint32 family_offset = 3;

  FeatureStats stats = 5;

  // The order of features within a family. FeatureFamily's index is 0-based. 
  int32 family_idx = 7;

  // True to have this feature in the final output.
  bool in_final = 8;
}

// Each data instance is stored as DatumProto, which has 6 data stores
// (see Feature).
message DatumProto {
  repeated int32 dense_cat_store = 1;   // dense categorical store
  repeated float dense_num_store = 2;   // dense numerical store
  repeated bytes dense_bytes_store = 3;   // dense byte store

  // Sparse stores are maps, each represented by an index array and a value
  // array.
  map<uint32, int32> sparse_cat_store = 4;
  map<uint32, float> sparse_num_store = 5;
  map<uint32, bytes> sparse_bytes_store = 6;
  //repeated uint32 sparse_cat_store_idx = 4;
  //repeated int32 sparse_cat_store_val = 5;
  //repeated uint32 sparse_num_store_idx = 6;
  //repeated float sparse_num_store_val = 7;
  //repeated uint32 sparse_bytes_store_idx = 8;
  //repeated bytes sparse_bytes_store_val = 9;
}

// FeatureFamily contains a set of offset to denote the start of family in
// each store of DatumProto/DatumBase. Schema maintains these offsets for the
// next family insertion.
message DatumBaseOffset {
  int32 dense_cat_store = 1;
  int32 dense_num_store = 2;
  int32 dense_bytes_store = 3;
  int32 sparse_cat_store = 4;
  int32 sparse_num_store = 5;
  int32 sparse_bytes_store = 6;
}

// Current max proto sequence: 5.
message FeatureFamilyProto {
  // Index lookup on family (e.g., "mobile:0" will find the first entry in
  // features).
  repeated Feature features = 1;

  // Map from feature name (string) to index on features, used in
  // "mobile:num_clicks" type of lookup (name = "num_clicks").
  repeated string name_lookup_idx = 2;
  repeated uint32 name_lookup_val = 3;

  DatumBaseOffset offset = 4;
}

// Current max proto sequence: 5.
message SchemaProto {
  // (yuwr:) This should also be id?
  // uint32 schema_id = 1;

  // version is defined based on user's schema evolution.
  // TODO(wdai): Do we need another internal schema_id, as Weiren suggested?
  uint32 version = 1;

  // name (string) --> FeatureFamilyProto. We support multi-weight and multi-labels
  // through specially reserved families 'label' and 'weight'.
  //
  // Comment(wdai): This map lookup will only be done once during transform to
  // get the index on DatumRecord stores, thus not performance critical.
  repeated string families_map_idx = 2;
  repeated FeatureFamilyProto families_map_val = 3;

  // # of CATEGORICAL and NUMERICAL features, excluding label, weight, and
  // bytes and unknowns.
  //
  // Comemnt: 'dim' can belong to DB level if we assume static schema.
  //uint64 dim = 4;

  DatumBaseOffset offset = 5;
}

enum Compressor {
  RAW = 0;
  ZIP = 1;
  RLE = 2;
}

// File is assumed to be stored in file chunks of a user defined fixed size (e.g. HDFS).
// Each file contains a number of data records.
// (The record would start with a length descriptor (4 bytes) used to segment each compressed record.
// This is taken care of by the underlying storage interface.)
message FileInfo {
  string filepath = 1;
  string filename = 2;
  uint32 filesize = 3; // in Bytes

  // timestamp in unix time of seconds.
  uint64 creationtime = 4;
  // # data records in the file 
  uint64 num_data = 5;
  // use datum# to locate its physical position on the file
  // e.g. If you have a 64MB file, you can add a few indices 
  // by the size of 4MB, to reduce sequential seek burden.
  // Comment(wdai): Let's not worry about this yet. Sequential read of 64MB
  // files are okay.
  //repeated map<uint64, uint64> data_idx= 6;
  Compressor compression_method = 7;
}

// Comment(wdai): Could you (Weiren) provide some comments explaining the use
// of these fields? Thanks!
message FileMap {
  int32 file_map_id = 1;
  repeated FileInfo files_info = 2;
}

enum StorageType {
  NFS = 0;
  HDFS = 1;
}

message DBMetaData {
  // Basic information about DB.
  string db_name = 3;
  string db_description = 4;
  uint32 num_epoch = 5;
  uint32 num_schema = 6; // could be retrieved from schema_id.size();
  StorageType storage_type = 7;
  // Database Creation Timestamp.
  uint64 creation_time = 8;

  // There should be a view of epochs in the current DB.
  repeated uint32 epoch_id = 1;
  // There should also be a view of schemas in the current DB
  repeated uint32 schema_id = 2;
}

// TODO(wdai): Define TSchema (TransformedSchema) that contains stats about
// each transformed column (e.g., estimated # of nonzeros, storage type,
// feature dim) so trainer and optimize based on these info.
