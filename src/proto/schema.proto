syntax = "proto3";

package mldb;

enum FeatureType {
  CATEGORICAL = 0;  // int32
  NUMERICAL = 1;    // float
  BYTES = 2;  // arbitrary byte string.
  // Comment(wdai): timestamp should be a numerical type (in seconds).
  // TODO(wdai): What if user wants to store double? Ignore this for now.
}

// FeatureStoreType should be determined by the frequency of a feature in
// a dataset. This can be inferred at first ingest (schema creation) or
// explicitly/manually determined by user.
//
// Comment(wdai): See Dato's nice column type inference from data.
enum FeatureStoreType {
  SPARSE = 0;
  DENSE = 1;
}

message FeatureStats {
  optional double mean = 1;
  optional double std = 2;
  optional double quantile_5 = 3;
  optional double quantile_95 = 4;
}

message EpochInfo {

  // Comment (yuwr:) This should be a schema index? We might have many
  // schemas, each schema could have many versions.  Each epoch would
  // correspond to a schema, but not vice versa, hence the index.
  //
  // Comment (wdai): Since schema really is just the mapping from "mobile:ctr"
  // feature descriptor to the feature id, I feel that this only needs to
  // change when (1) user changes schema explicitly, or (2) we change the
  // internal descriptor to feature_id mapping. I feel (2) could be too costly
  // to do and thus we only needs one version id.

  // optional uint32 schema_id = 1;
  optional uint32 schema_version = 1;   // for schema evolution (future work).

  // # data in this epoch.
  optional uint64 num_data = 1;

  // # of outlier data determined at ingest time.
  optional uint64 num_outliers = 3;

  // Ingest period in unix time seconds.
  optional uint64 ingest_time_begin = 4;
  optional uint64 ingest_time_end = 5;

  // Comment(wdai): We might want to maintain per-epoch stats since the user
  // can query data from a range of epochs but not the whole.  stats is
  // maintained at ingest time.
  repeated FeatureStats stats = 2;
  // We assue each epoch would have one single FileMap object to locate the files.
  // We use the file map index to located the object, avoiding ojbect inconsistency.
  optional uint32 file_map_id= 7;
}

// Feature locates the feature value in DatumRecord, which has 6 data stores
// (3 FeatureType x 2 FeatureStoreType). FeatureType and FeatureStorage type
// identify the store in DatumRecord, and idx searches for the value in the
// appropriate store.
message Feature {
  optional FeatureType type = 1 [default = CATEGORICAL];
  optional FeatureStoreType storage_type = 2 [default = SPARSE];

  // Locate feature value in the store. It represents the index for dense
  // store (vector) or key in sparse store (map). For map lookup, not found
  // means 0. This index is determined at schema creation.
  optional uint32 idx = 3;

  // Comment(yuwr): How is this implemented since the FeatureStat object does
  // not have a index in its schema definition. I am not sure abou this so I
  // defined an explicit index in the schema definition.
  //
  // idx on EpochInfo.stats vector.
  optional uint32 stats_idx;
}

// Each data instance is stored as DatumRecord, which has 6 data stores
// (see Feature).
message DatumRecord {
  repeated int32 dense_cat_store = 1;   // dense categorical store
  repeated float dense_num_store = 2;   // dense numerical store
  repeated bytes dense_bytes_store = 3;   // dense byte store

  // Comment(wdai): Map lookup can be expensive at transform time. Consider
  // using double vectors (which is the way protobuf stores map
  // object) sorted on uint32 key.
  map<uint32, int32> sparse_cat_store = 4;
  map<uint32, float> sparse_num_store = 5;
  map<uint32, bytes> sparse_bytes_store = 6;
}

message FeatureFamily {
  // Index lookup on family (e.g., "mobile:0" will find the first entry in
  // features).
  repeated Feature features = 1;

  // Map from feature name (string) to index on features, used in
  // "mobile:num_clicks" type of lookup.
  map<string, uint32> name_to_features_idx = 2;
}

message Schema {
  // (yuwr:) This should also be id?
  // optional uint32 schema_id = 1 [default = 0];

  // version is defined based on user's schema evolution.
  // TODO(wdai): Do we need another internal schema_id, as Weiren suggested?
  optional uint32 version = 1 [default = 0];

  // name (string) --> FeatureFamily. We support multi-weight and multi-labels
  // through specially reserved families 'label' and 'weight'.
  //
  // Comment(wdai): This map lookup will only be done once during transform to
  // get the index on DatumRecord stores, thus not performance critical.
  map<string, FeatureFamily> families = 2;

  // # of CATEGORICAL and NUMERICAL features, excluding label, weight, and
  // bytes.
  //
  // Comemnt: 'dim' can belong to DB level if we assume static schema.
  optional uint64 dim = 1;
} 

enum Compressor {
  RAW = 1;
  ZIP = 2;
  RLE = 3;
}

// File is assumed to be stored in file chunks of a user defined fixed size (e.g. HDFS).
// Each file contains a number of data records.
// (The record would start with a length descriptor (4 bytes) used to segment each compressed record.
// This is taken care of by the underlying storage interface.)
message FileInfo {
  optional string filepath = 1;
  optional string filename = 2;
  optional uint32 filesize = 3; // in Bytes
  
  // timestamp in unix time of seconds.
  optional uint64 creationtime = 4;
  // # data records in the file 
  optional uint64 num_data = 5;
  // use datum# to locate its physical position on the file
  // e.g. If you have a 64MB file, you can add a few indices 
  // by the size of 4MB, to reduce sequential seek burden.
  repeated map<uint64, uint64> data_idx= 6;
  optional Compressor compression_method = 7 [default = RAW];
}

// Comment(wdai): Could you (Weiren) provide some comments explaining the use
// of these fields? Thanks!
message FileMap {
  optional file_map_id = 1;
  repeated FileInto files_info = 2;
}

enum StorageType {
  NFS = 1;
  HDFS = 2;
}

message DBMetaData {
  // Basic information about DB.
  optional string db_name = 3;
  optional string db_description = 4;
  optional uint32 num_epoch = 5;
  optional uint32 num_schema = 6; // could be retrieved from schema_id.size();
  optional StorageType storage_type = 7 [default = NFS];
  // Database Creation Timestamp.
  optional uint64 creation_time = 8;
  
  // There should be a view of epochs in the current DB.
  repeated uint32 epoch_id = 1;
  // There should also be a view of schemas in the current DB
  repeated uint32 schema_id = 2;
}

// TODO(wdai): Define TSchema (TransformedSchema) that contains stats about
// each transformed column (e.g., estimated # of nonzeros, storage type,
// feature dim) so trainer and optimize based on these info.
